# Social Media Image Captioning
Deployed apps : https://social-media-captioning.streamlit.app/ <br>
<br>


- PPT: https://www.canva.com/design/DAG7XDYFt2I/bEKJJIOpGMf_becPWhr3Vw/edit?utm_content=DAG7XDYFt2I&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton  

<br>

## Project Description
This project aims to develop an advanced automatic image captioning system that generates objective descriptions of image content and adapts the style of these descriptions for social media uploads, complete with relevant hashtags.

1.  **Visual Feature Extraction:** Utilizes the `EfficientNetB0` architecture as an encoder to extract key visual features from images.
2.  **Objective Caption Generation:** Transformer architecture as a decoder to translate these visual features into accurate textual captions.
3.  **Social Media Style Adaptation:** The raw captions generated by the model are passed as context to the **Mistral Small 24B LLM** via API to reproduce social media colloquialisms and append appropriate hashtags.

<br>

## Outline Architecture
1.  **Input:** An image is uploaded to the system.
2.  **Encoder (EfficientNetB0):** The image is processed to generate feature representations.
3.  **Decoder (Transformer):** Features are translated into a raw, objective caption.
4.  **Prompt Engineering:** The **predicted caption(from model)** is used within a prompt sent to the Mistral API.
5.  **LLM (Mistral Small 24B):** The LLM converts the **predicted caption** into a social media-ready caption (+ hashtags).
6.  **Output:** The final upload-ready text.

<br>

### Folder Descriptions:

*   **`apps/`**: Contains code for the user interface or API running the model in a production environment.
*   **`data/`**: Storage location for link to COCO 2017 subset dataset (10K train/2K val) in HuggingFace, link to raw (.zip)
*   **`notebooks/`**: Location for experiments, complete pipeline EfficientNet-Transformer model.
*   **`reports/`**: Contains final reports and project presentation slides.
*   **`src/`**: data collection & processing utilities, vocab, and .json evaluation results(import to get evaluation metrics)

<br>

## Dataset
This project leverages a public subset of the **COCO 2017 Captioning dataset**.
